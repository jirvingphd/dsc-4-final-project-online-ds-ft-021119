{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Million Russian Troll Tweets\n",
    "- James M Irving, Ph.D.\n",
    "- Mod 4 Project\n",
    "- Flatiron Full Time Data Science Bootcamp - 02/2019 Cohort\n",
    "\n",
    "## GOAL: \n",
    "\n",
    "- *IF I can get a control dataset* of non-Troll tweets from same time period with similar hashtags:*\n",
    "    - Use NLP to predict of a tweet is from an authentic user or a Russian troll.\n",
    "- *If no control tweets to compare to*\n",
    "    - Use NLP to predict how many retweets a Troll tweet will get.\n",
    "    - Consider both raw # of retweets, as well as a normalized # of retweets/# of followers.\n",
    "        - The latter would give better indication of language's effect on propagation. \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Features:\n",
    "- Kaggle Dataset published by FiveThirtyEight\n",
    "    - https://www.kaggle.com/fivethirtyeight/russian-troll-tweets/downloads/russian-troll-tweets.zip/2\n",
    "<br>    \n",
    "- Data is split into 9 .csv files\n",
    "    - 'IRAhandle_tweets_1.csv' to 9\n",
    "\n",
    "- **Variables:**\n",
    "    - ~~`external_author_id` | An author account ID from Twitter~~\n",
    "    - `author` | The handle sending the tweet\n",
    "    - `content` | The text of the tweet\n",
    "    - `region` | A region classification, as [determined by Social Studio](https://help.salesforce.com/articleView?   id=000199367&type=1)\n",
    "    - `language` | The language of the tweet\n",
    "    - `publish_date` | The date and time the tweet was sent\n",
    "    - ~~`harvested_date` | The date and time the tweet was collected by Social Studio~~\n",
    "    - `following` | The number of accounts the handle was following at the time of the tweet\n",
    "    - `followers` | The number of followers the handle had at the time of the tweet\n",
    "    - `updates` | The number of “update actions” on the account that authored the tweet, including tweets, retweets and likes\n",
    "    - `post_type` | Indicates if the tweet was a retweet or a quote-tweet *[Whats a quote-tweet?]*\n",
    "    - `account_type` | Specific account theme, as coded by Linvill and Warren\n",
    "    - `retweet` | A binary indicator of whether or not the tweet is a retweet [?]\n",
    "    - `account_category` | General account theme, as coded by Linvill and Warren\n",
    "    - `new_june_2018` | A binary indicator of whether the handle was newly listed in June 2018\n",
    "    \n",
    "### **Classification of account_type**\n",
    "Taken from: [rcmediafreedom.eu summary](https://www.rcmediafreedom.eu/Publications/Academic-sources/Troll-Factories-The-Internet-Research-Agency-and-State-Sponsored-Agenda-Building)\n",
    "\n",
    ">- **They identified five categories of IRA-associated Twitter accounts, each with unique patterns of behaviors:**\n",
    "    - **Right Troll**, spreading nativist and right-leaning populist messages. It supported the candidacy and Presidency of Donald Trump and denigrated the Democratic Party. It often sent divisive messages about mainstream and moderate Republicans.\n",
    "    - **Left Troll**, sending socially liberal messages and discussing gender, sexual, religious, and -especially- racial identity. Many tweets seemed intentionally divisive, attacking mainstream Democratic politicians, particularly Hillary Clinton, while supporting Bernie Sanders prior to the election.\n",
    "    - **News Feed**, overwhelmingly presenting themselves as U.S. local news aggregators, linking to legitimate regional news sources and tweeting about issues of local interest.\n",
    "    - **Hashtag Gamer**, dedicated almost exclusively to playing hashtag games.\n",
    "    - **Fearmonger**: spreading a hoax about poisoned turkeys near the 2015 Thanksgiving holiday.\n",
    "\n",
    ">The different types of account were used differently and their efforts were conducted systematically, with different allocation when faced with different political circumstances or shifting goals. E.g.: there was a spike of activity by right and left troll accounts before the publication of John Podesta's emails by WikiLeaks. According to the authors, this activity can be characterised as “industrialized political warfare”.\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View our documentation at https://bs-ds.readthedocs.io/en/latest/index.html\n",
      "For convenient loading of standard modules :\n",
      ">> from bs_ds.imports import *\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Module/Package Handle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pandas</th>\n",
       "      <td>pd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numpy</th>\n",
       "      <td>np</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>matplotlib</th>\n",
       "      <td>mpl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>matplotlib.pyplot</th>\n",
       "      <td>plt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seaborn</th>\n",
       "      <td>sns</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Module/Package Handle\n",
       "pandas                               pd\n",
       "numpy                                np\n",
       "matplotlib                          mpl\n",
       "matplotlib.pyplot                   plt\n",
       "seaborn                             sns"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import bs_ds as bs\n",
    "from bs_ds.imports import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "root_dir = 'russian-troll-tweets/'\n",
    "# os.listdir('russian-troll-tweets/')\n",
    "filelist = [os.path.join(root_dir,file) for file in os.listdir(root_dir) if file.endswith('.csv')]\n",
    "filelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previewing dataset\n",
    "df = pd.read_csv(filelist[0])\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vertically concatenate \n",
    "for file in filelist:\n",
    "    df_new = pd.read_csv(file)\n",
    "    df = pd.concat([df,df_new], axis=0)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCRUBBING/EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from pandas_profiling import ProfileReport\n",
    "ProfileReport(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations from Inspection / Pandas_Profiling ProfileReport\n",
    "\n",
    "- **Language to Analyze is in `Content`:**\n",
    "    - Actual tweet contents. \n",
    " \n",
    "- **Classification/Analysis Thoughts:**\n",
    "    - **Variables should be considered in 2 ways:**\n",
    "        - First, the tweet contents. \n",
    "            - Use NLP to engineer features to feed into deep learning.\n",
    "                - Sentiment analysis, named-entity frequency/types, most-similar words. \n",
    "        - Second, the tweet metadata. \n",
    "        \n",
    "### Thoughts on specific features:\n",
    "- `language`\n",
    "    - There are 56 unique languages. \n",
    "    - 2.4 million are English, 670 K are in Russian, etc.\n",
    "    - Note: for metadata, analyzing if an account posts in more than 1 language may be a good predictor. \n",
    "- `followers`/`following`\n",
    "    - **following** could be informative if goal is to predict if its a troll tweet.\n",
    "    - **followers** should be used (with retweets) if predicting retweets based on content. \n",
    "\n",
    "- **Questions:**\n",
    "    - [ ] Why are so many post_types missing? (55%?)\n",
    "    \n",
    "### Scrubing to Perform\n",
    "- **Recast Columns:**\n",
    "    - [ ] `publish_date` to datetime. \n",
    "- **Columns to Discard:**\n",
    "    - [ ] `external_author_id` ( we have author handle)\n",
    "    - [ ] `harvested_date` (we care about publish_date, if anything, time-wise)\n",
    "    - [ ] `language`: remove all non-english tweets and drop column\n",
    "    - [ ] `new_june_2018`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop non-english rows\n",
    "df = df.loc[df.language=='English']\n",
    "# df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = ['external_author_id','harvested_date','new_june_2018']#: remove all non-english tweets and drop column\n",
    "\n",
    "for col in cols_to_drop:\n",
    "    df.drop(col, axis=1, inplace=True)\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recasting Publish date as datetime column (date_published)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert publish_date to datetime\n",
    "df['date_published'] = pd.to_datetime(df.publish_date)\n",
    "print(np.max(df.date_published), np.min(df.date_published))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index('date_published',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Save/Load and Resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save csv\n",
    "# df.to_csv('russian_troll_tweets_eng_only_date_pub_index.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bs.check_unique(df,['region'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bs_ds v. 0.7.2 ... read the docs at https://bs-ds.readthedocs.io/en/latest/index.html\n",
      "For convenient loading of standard modules :\n",
      ">> from bs_ds.imports import *\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\james\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Module/Package Handle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pandas</th>\n",
       "      <td>pd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numpy</th>\n",
       "      <td>np</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>matplotlib</th>\n",
       "      <td>mpl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>matplotlib.pyplot</th>\n",
       "      <td>plt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seaborn</th>\n",
       "      <td>sns</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Module/Package Handle\n",
       "pandas                               pd\n",
       "numpy                                np\n",
       "matplotlib                          mpl\n",
       "matplotlib.pyplot                   plt\n",
       "seaborn                             sns"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changed index to datetime \"date_published\".\n",
      "Dropped publish_date.\n",
      "Dropped language.\n",
      "Converted region to category.\n",
      "Converted post_type to category.\n",
      "Converted account_type to category.\n",
      "Converted account_category to category.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "      <th>region</th>\n",
       "      <th>following</th>\n",
       "      <th>followers</th>\n",
       "      <th>updates</th>\n",
       "      <th>post_type</th>\n",
       "      <th>account_type</th>\n",
       "      <th>retweet</th>\n",
       "      <th>account_category</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_published</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-10-01 19:58:00</th>\n",
       "      <td>10_GOP</td>\n",
       "      <td>\"We have a sitting Democrat US Senator on tria...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1052</td>\n",
       "      <td>9636</td>\n",
       "      <td>253</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Right</td>\n",
       "      <td>0</td>\n",
       "      <td>RightTroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-01 22:43:00</th>\n",
       "      <td>10_GOP</td>\n",
       "      <td>Marshawn Lynch arrives to game in anti-Trump s...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1054</td>\n",
       "      <td>9637</td>\n",
       "      <td>254</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Right</td>\n",
       "      <td>0</td>\n",
       "      <td>RightTroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-01 22:50:00</th>\n",
       "      <td>10_GOP</td>\n",
       "      <td>Daughter of fallen Navy Sailor delivers powerf...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1054</td>\n",
       "      <td>9637</td>\n",
       "      <td>255</td>\n",
       "      <td>RETWEET</td>\n",
       "      <td>Right</td>\n",
       "      <td>1</td>\n",
       "      <td>RightTroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-01 23:52:00</th>\n",
       "      <td>10_GOP</td>\n",
       "      <td>JUST IN: President Trump dedicates Presidents ...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1062</td>\n",
       "      <td>9642</td>\n",
       "      <td>256</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Right</td>\n",
       "      <td>0</td>\n",
       "      <td>RightTroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-01 02:13:00</th>\n",
       "      <td>10_GOP</td>\n",
       "      <td>19,000 RESPECTING our National Anthem! #StandF...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1050</td>\n",
       "      <td>9645</td>\n",
       "      <td>246</td>\n",
       "      <td>RETWEET</td>\n",
       "      <td>Right</td>\n",
       "      <td>1</td>\n",
       "      <td>RightTroll</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     author  \\\n",
       "date_published                \n",
       "2017-10-01 19:58:00  10_GOP   \n",
       "2017-10-01 22:43:00  10_GOP   \n",
       "2017-10-01 22:50:00  10_GOP   \n",
       "2017-10-01 23:52:00  10_GOP   \n",
       "2017-10-01 02:13:00  10_GOP   \n",
       "\n",
       "                                                               content  \\\n",
       "date_published                                                           \n",
       "2017-10-01 19:58:00  \"We have a sitting Democrat US Senator on tria...   \n",
       "2017-10-01 22:43:00  Marshawn Lynch arrives to game in anti-Trump s...   \n",
       "2017-10-01 22:50:00  Daughter of fallen Navy Sailor delivers powerf...   \n",
       "2017-10-01 23:52:00  JUST IN: President Trump dedicates Presidents ...   \n",
       "2017-10-01 02:13:00  19,000 RESPECTING our National Anthem! #StandF...   \n",
       "\n",
       "                      region  following  followers  updates post_type  \\\n",
       "date_published                                                          \n",
       "2017-10-01 19:58:00  Unknown       1052       9636      253       NaN   \n",
       "2017-10-01 22:43:00  Unknown       1054       9637      254       NaN   \n",
       "2017-10-01 22:50:00  Unknown       1054       9637      255   RETWEET   \n",
       "2017-10-01 23:52:00  Unknown       1062       9642      256       NaN   \n",
       "2017-10-01 02:13:00  Unknown       1050       9645      246   RETWEET   \n",
       "\n",
       "                    account_type  retweet account_category  \n",
       "date_published                                              \n",
       "2017-10-01 19:58:00        Right        0       RightTroll  \n",
       "2017-10-01 22:43:00        Right        0       RightTroll  \n",
       "2017-10-01 22:50:00        Right        1       RightTroll  \n",
       "2017-10-01 23:52:00        Right        0       RightTroll  \n",
       "2017-10-01 02:13:00        Right        1       RightTroll  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import bs_ds as bs\n",
    "from bs_ds.imports import *\n",
    "# Load csva\n",
    "df = pd.read_csv('russian_troll_tweets_eng_only_date_pub_index.csv')\n",
    "\n",
    "# Recast date_published as datetime and make index\n",
    "df.date_published = pd.to_datetime(df['date_published'])\n",
    "df.set_index('date_published', inplace=True)\n",
    "print('Changed index to datetime \"date_published\".')\n",
    "\n",
    "# Drop un-needed columns\n",
    "cols_to_drop = ['publish_date','language']\n",
    "for col in cols_to_drop:\n",
    "    \n",
    "    df.drop(col, axis=1, inplace=True)\n",
    "    print(f'Dropped {col}.')\n",
    "    \n",
    "    \n",
    "# Recast categorical columns\n",
    "cols_to_cats = ['region','post_type','account_type','account_category']\n",
    "for col in cols_to_cats:\n",
    "    \n",
    "    df[col] = df[col].astype('category')\n",
    "    print(f'Converted {col} to category.')\n",
    "\n",
    "\n",
    "# Drop problematic nan in 'contet'\n",
    "df.dropna(subset=['content'],inplace=True) # Dropping the 1 null value \n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bs.big_pandas()\n",
    "# pd.set_option('display.max_info_columns',500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 2420533 entries, 2017-10-01 19:58:00 to 2015-08-13 11:19:00\n",
      "Data columns (total 10 columns):\n",
      "author              object\n",
      "content             object\n",
      "region              category\n",
      "following           int64\n",
      "followers           int64\n",
      "updates             int64\n",
      "post_type           category\n",
      "account_type        category\n",
      "retweet             int64\n",
      "account_category    category\n",
      "dtypes: category(4), int64(4), object(2)\n",
      "memory usage: 138.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thoughts on My Search Strategy\n",
    "\n",
    "**My Twitter API Link:**<br>\n",
    "https://api.twitter.com/1.1/tweets/search/fullarchive/search.json\n",
    "\n",
    "\n",
    "**Inspect Data to get search parameters:**\n",
    "- [X] Get the date range for the English tweets in the original dataset<br>\n",
    "    - **Tweet date range:**\n",
    "        - **2012-02-06** to **2018-05-30**\n",
    "\n",
    "- [X] Get a list of the hash tags (and their frequencies from the dataframe\n",
    "\n",
    "**Determine most feasible and balanced well of extracting control tweets**\n",
    "- [ ] How many of each tag / @'s should I try to exctract?\n",
    "- [ ] what are the limitations of the API that will be a road block to getting as many tweets as desired?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet date range:\n",
      " 2012-02-06 20:24:00 to 2018-05-30 20:58:00\n",
      "\n",
      "Total days: 2305 days 00:34:00\n"
     ]
    }
   ],
   "source": [
    "# Inspect Data to get search parameters:\n",
    "print(f'Tweet date range:\\n {min(df.index)} to {max(df.index)}')\n",
    "print(f'\\nTotal days: {max(df.index)-min(df.index)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determining Hashtags & @'s\n",
    "\n",
    "- Use regular expressions to extract the hashtags #words and @handles.\n",
    "- Use the top X many tags as search terms for twitter API\n",
    "    - There are _1,678,170 unique hashtags_ and _1,165,744 unique @'s_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define get_tags_ats to accept a list of text entries and return all found tags and ats as 2 series/lists\n",
    "def get_tags_ats(text_to_search,exp_tag = r'(#\\w*)',exp_at = r'(@\\w*)', output='series',show_counts=False):\n",
    "    \"\"\"Accepts a list of text entries to search, and a regex for tags, and a regex for @'s.\n",
    "    Joins all entries in the list of text and then re.findsall() for both expressions.\n",
    "    Returns a series of found_tags and a series of found_ats.'\"\"\"\n",
    "    import re\n",
    "    \n",
    "    # Create a single long joined-list of strings\n",
    "    text_to_search_combined = ' '.join(text_to_search)\n",
    "        \n",
    "    # print(len(text_to_search_combined), len(text_to_search_list))\n",
    "    found_tags = re.findall(exp_tag, text_to_search_combined)\n",
    "    found_ats = re.findall(exp_at, text_to_search_combined)\n",
    "    \n",
    "    if output.lower() == 'series':\n",
    "        found_tags = pd.Series(found_tags, name='tags')\n",
    "        found_ats = pd.Series(found_ats, name='ats')\n",
    "        \n",
    "        if show_counts==True:\n",
    "            print(f'\\t{found_tags.name}:\\n{tweet_tags.value_counts()} \\n\\n\\t{found_ats.name}:\\n{tweet_ats.value_counts()}')\n",
    "                \n",
    "    if (output.lower() != 'series') & (show_counts==True):\n",
    "        raise Exception('output must be set to \"series\" in order to show_counts')\n",
    "                       \n",
    "    return found_tags, found_ats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\"We have a sitting Democrat US Senator on trial for corruption and you\\'ve barely heard a peep from the mainstream media.\" ~ @nedryun https://t.co/gh6g0D1oiC',\n",
       " 'Marshawn Lynch arrives to game in anti-Trump shirt. Judging by his sagging pants the shirt should say Lynch vs. belt https://t.co/mLH1i30LZZ']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Need to get a list of hash tags.\n",
    "text_to_search_list = []\n",
    "\n",
    "for i in range(len(df)):    \n",
    "    tweet_contents =df['content'].iloc[i]\n",
    "    text_to_search_list.append(tweet_contents)\n",
    "\n",
    "text_to_search_list[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 1678170 unique hashtags and 1165744 unique @'s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get all tweet tags and @'s from text_to_search_list\n",
    "tweet_tags, tweet_ats = get_tags_ats(text_to_search_list, show_counts=False)\n",
    "\n",
    "print(f\"There were {len(tweet_tags)} unique hashtags and {len(tweet_ats)} unique @'s\\n\")\n",
    "\n",
    "# Create a dataframe with top_tags\n",
    "df_top_tags = pd.DataFrame(tweet_tags.value_counts()[:40])#,'\\n')\n",
    "df_top_tags['% Total'] = (df_top_tags['tags']/len(tweet_tags)*100)\n",
    "\n",
    "# Create a dataframe with top_ats\n",
    "df_top_ats = pd.DataFrame(tweet_ats.value_counts()[:40])\n",
    "df_top_ats['% Total'] = (df_top_ats['ats']/len(tweet_ats)*100)\n",
    "\n",
    "# Display top tags and ats\n",
    "# bs.display_side_by_side(df_top_tags,df_top_ats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes on Top Tags and Ats:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The most common tags include some very generic categories that may not be helpful in extracting control tweets.\n",
    "    - ~~Exclude: '#news','#sports','#politics','#world','#local','#TopNews','#health','#business','#tech',~~\n",
    "    - On second thought, this is entirely appropriate, since these tags would be what appears in the wild.\n",
    "    - Additionally, using a larger number of them (like 30, starts to provide more targeted hashtags.<br><br>\n",
    "  \n",
    "- **The most common @'s are much more revealing and helpful in narrowing the focus of the results.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['#news', '#sports', '#politics', '#world', '#local', '#MAGA',\n",
       "       '#BlackLivesMatter', '#TopNews', '#tcot', '#PJNET', '#health',\n",
       "       '#business', '#tech', '#entertainment', '#top', '#Cleveland', '#crime',\n",
       "       '#TopVideo', '#Trump', '#NowPlaying', '#amb', '#environment', '#ISIS',\n",
       "       '#breaking', '#mar', '#WakeUpAmerica', '#Miami', '#2A', '#GOPDebate',\n",
       "       '#topl'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose list of top tags to use in search\n",
    "list_top_30_tags = df_top_tags.index[:30]\n",
    "list_top_30_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['@realDonaldTrump', '@midnight', '@POTUS', '@HillaryClinton',\n",
       "       '@YouTube', '@', '@CNN', '@FoxNews', '@TalibKweli', '@WarfareWW',\n",
       "       '@GiselleEvns', '@WorldOfHashtags', '@deray', '@nytimes', '@josephjett',\n",
       "       '@CNNPolitics', '@GOP', '@seanhannity', '@BreitbartNews',\n",
       "       '@BarackObama', '@HashtagRoundup', '@tedcruz', '@washingtonpost',\n",
       "       '@docrocktex26', '@ShaunKing', '@BernieSanders', '@VanJones68',\n",
       "       '@mashable', '@Jenn_Abrams', '@SpeakerRyan'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose list of top tags to use in search\n",
    "list_top_30_ats = df_top_ats.index[:30]\n",
    "list_top_30_ats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the Twitter Search API to Extract Control Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x] Required API key are saved in the Main folder in which this repo is saved. \n",
    "- [x] Check the [Premium account docs for search syntax](https://developer.twitter.com/en/docs/tweets/search/guides/premium-operators.html)\n",
    "- [x] [Check this article for using Tweepy for most efficient twitter api extraction](https://bhaskarvk.github.io/2015/01/how-to-use-twitters-search-rest-api-most-effectively./)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LINK TO PREMIUM SEARCH API GUIDE**<br>\n",
    "https://developer.twitter.com/en/docs/tweets/search/api-reference/premium-search\n",
    "\n",
    "### Available operators\n",
    "- Premium search API supports rules with up to 1,024 characters. The Search Tweets APIs support the premium operators listed below. See our Premium operators guide for more details.\n",
    "\n",
    "- The base URI for the premium search API is https://api.twitter.com/1.1/tweets/search/.\n",
    "\n",
    "**Matching on Tweet contents:**\n",
    "- keyword\n",
    "- \"quoted phrase\"\n",
    "- #\n",
    "- @\n",
    "- url:\n",
    "- lang:\n",
    "\n",
    "\n",
    "**API Post Search Methods**\n",
    "- POST /search/:product/:label\t\n",
    "    - Retrieve Tweets matching the specified query.\n",
    "- POST /search/:product/:label/counts\t\n",
    "    - Retrieve the number of Tweets matching the specified query.\n",
    "- where:\n",
    "    - `:product` indicates the search endpoint you are making requests to, either 30day or fullarchive.\n",
    "    - `:label` is the (case-sensitive) label associated with your search developer environment, as displayed at https://developer.twitter.com/en/account/environments.\n",
    "- For example, if using the 30-day endpoint and your dev environment has a label of 'dev' (short for development), the search URLs would be:\n",
    "    - Data endpoint providing Tweets: https://api.twitter.com/1.1/tweets/search/30day/dev.json\n",
    "    - Counts endpoint providing counts of Tweets: https://api.twitter.com/1.1/tweets/search/30day/dev/counts.json\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using tweepy to access twitter API\n",
    "\n",
    "- [Helpful tutorial on _most efficient_ way to access twitter API](https://bhaskarvk.github.io/2015/01/how-to-use-twitters-search-rest-api-most-effectively./)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy, sys\n",
    "\n",
    "api_key = \n",
    "api_secret_key  = \n",
    "\n",
    "auth = tweepy.AppAuthHandler(api_key, api_secret_key)\n",
    "\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)\n",
    "\n",
    "if (not api):\n",
    "    print(\"Can't authenticate.\")\n",
    "    sys.exit(-1)\n",
    "# auth = tweepy.OAuthHandler(consumer_token, consumer_secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "@realDonaldTrump    14999\n",
       "@midnight            9991\n",
       "@POTUS               5633\n",
       "@HillaryClinton      5052\n",
       "@YouTube             4484\n",
       "@                    3758\n",
       "@CNN                 3358\n",
       "@FoxNews             3284\n",
       "@TalibKweli          2064\n",
       "@WarfareWW           1600\n",
       "@GiselleEvns         1359\n",
       "@WorldOfHashtags     1281\n",
       "@deray               1205\n",
       "@nytimes             1198\n",
       "@josephjett          1164\n",
       "@CNNPolitics         1163\n",
       "@GOP                 1136\n",
       "@seanhannity         1073\n",
       "@BreitbartNews       1006\n",
       "@BarackObama          995\n",
       "@HashtagRoundup       947\n",
       "@tedcruz              909\n",
       "@washingtonpost       824\n",
       "@docrocktex26         814\n",
       "@ShaunKing            811\n",
       "@BernieSanders        807\n",
       "@VanJones68           802\n",
       "@mashable             790\n",
       "@Jenn_Abrams          756\n",
       "@SpeakerRyan          746\n",
       "@jstines3             728\n",
       "@AC360                703\n",
       "@CNNSitRoom           683\n",
       "@KeshaTedder          681\n",
       "@JakeTapper           677\n",
       "@MariaSharapova       670\n",
       "@TheLeadCNN           661\n",
       "@WolfBlitzer          658\n",
       "@BrianStelter         657\n",
       "@CNNI                 655\n",
       "Name: ats, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_top_ats.ats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of top tags = 525668\n",
      "Sum of top @'s = 80782\n"
     ]
    }
   ],
   "source": [
    "# Calculate how many tweets are represented by the top 30 tags and top 30 @'s \n",
    "sum_top_tweet_tags = df_top_tags['tags'].sum()\n",
    "sum_top_tweet_ats = df_top_ats['ats'].sum()\n",
    "print(f\"Sum of top tags = {sum_top_tweet_tags}\\nSum of top @'s = {sum_top_tweet_ats}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure out the # of each @ and each # that i want ot query, then make a query_dict to feed into the cell below\n",
    "query_ats = tuple(zip(df_top_ats.index, df_top_ats['ats']))\n",
    "auery_tags = tuple(zip(df_top_tags.index, df_top_tags['tags']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('@realDonaldTrump', 14999),\n",
       " ('@midnight', 9991),\n",
       " ('@POTUS', 5633),\n",
       " ('@HillaryClinton', 5052),\n",
       " ('@YouTube', 4484),\n",
       " ('@', 3758),\n",
       " ('@CNN', 3358),\n",
       " ('@FoxNews', 3284),\n",
       " ('@TalibKweli', 2064),\n",
       " ('@WarfareWW', 1600),\n",
       " ('@GiselleEvns', 1359),\n",
       " ('@WorldOfHashtags', 1281),\n",
       " ('@deray', 1205),\n",
       " ('@nytimes', 1198),\n",
       " ('@josephjett', 1164),\n",
       " ('@CNNPolitics', 1163),\n",
       " ('@GOP', 1136),\n",
       " ('@seanhannity', 1073),\n",
       " ('@BreitbartNews', 1006),\n",
       " ('@BarackObama', 995),\n",
       " ('@HashtagRoundup', 947),\n",
       " ('@tedcruz', 909),\n",
       " ('@washingtonpost', 824),\n",
       " ('@docrocktex26', 814),\n",
       " ('@ShaunKing', 811),\n",
       " ('@BernieSanders', 807),\n",
       " ('@VanJones68', 802),\n",
       " ('@mashable', 790),\n",
       " ('@Jenn_Abrams', 756),\n",
       " ('@SpeakerRyan', 746),\n",
       " ('@jstines3', 728),\n",
       " ('@AC360', 703),\n",
       " ('@CNNSitRoom', 683),\n",
       " ('@KeshaTedder', 681),\n",
       " ('@JakeTapper', 677),\n",
       " ('@MariaSharapova', 670),\n",
       " ('@TheLeadCNN', 661),\n",
       " ('@WolfBlitzer', 658),\n",
       " ('@BrianStelter', 657),\n",
       " ('@CNNI', 655))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_ats\n",
    "# searchQuery = '@realDonaldTrump'\n",
    "# maxTweets = 500\n",
    "# tweetsPerQry = 100 \n",
    "# fName = 'extracted_tweets.txt'\n",
    "\n",
    "# max_id = 0\n",
    "# sinceId = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_twitter_api(searchQuery, maxTweets, fName, tweetsPerQry=100, max_id=0, sinceId=None):\n",
    "    import sys, jsonpickle, os\n",
    "\n",
    "    tweetCount = 0\n",
    "    print(f'Downloading max{maxTweets} for {searchQuery}...')\n",
    "    with open(fName, 'a+') as f:\n",
    "        while tweetCount < maxTweets:\n",
    "\n",
    "            try:\n",
    "                if (max_id <=0):\n",
    "                    if (not sinceId):\n",
    "                        new_tweets = api.search(q=searchQuery, count=tweetsPerQry, tweet_mode='extended')\n",
    "                    else:\n",
    "                        new_tweets = api.search(q=searchQuery, count=tweetsPerQry, since_id=sinceId, tweet_mode='extended')\n",
    "\n",
    "                else:\n",
    "                    if (not sinceId):\n",
    "                        new_tweets = api.search(q=searchQuery, count=tweetsPerQry, max_id=str(max_id-1), tweet_mode='extended')\n",
    "                    else:\n",
    "                        new_tweets = api.search(q=searchQuery, count=tweetsPerQry, max_id=str(max_id-1),since_id=sinceId, tweet_mode='extended')\n",
    "\n",
    "                if not new_tweets:\n",
    "                    print('No more tweets found')\n",
    "                    break\n",
    "\n",
    "                for tweet in new_tweets:\n",
    "                    f.write(jsonpickle.encode(tweet._json, unpicklable=False)+'\\n')\n",
    "\n",
    "                tweetCount+=len(new_tweets)\n",
    "\n",
    "                print(\"Downloaded {0} tweets\".format(tweetCount))\n",
    "                max_id = new_tweets[-1].id\n",
    "\n",
    "            except tweepy.TweepError as e:\n",
    "                # Just exit if any error\n",
    "                print(\"some error : \" + str(e))\n",
    "                break\n",
    "    print (\"Downloaded {0} tweets, Saved to {1}\\n\".format(tweetCount, fName))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bs_ds v. 0.7.4 ... read the docs at https://bs-ds.readthedocs.io/en/latest/index.html\n",
      "For convenient loading of standard modules :\n",
      ">> from bs_ds.imports import *\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\james\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "class Clock(object):\n",
    "    \"\"\"A clock meant to be used as a timer for functions using local time.\n",
    "    Clock.tic() starts the timer, .lap() adds the current laps time to clock._list_lap_times, .toc() stops the timer.\n",
    "    If user initiializes with verbose =0, only start and final end times are displays.\n",
    "        If verbose=1, print each lap's info at the end of each lap.\n",
    "        If verbose=2 (default, display instruction line, return datafarme of results.)\n",
    "    \"\"\"\n",
    "    from datetime import datetime\n",
    "    from pytz import timezone\n",
    "    from tzlocal import get_localzone\n",
    "    from bs_ds import list2df\n",
    "\n",
    "    def get_time(self,local=True):\n",
    "        \"\"\"Returns current time, in local time zone by default (local=True).\"\"\"\n",
    "        from datetime import datetime\n",
    "        from pytz import timezone\n",
    "        from tzlocal import get_localzone\n",
    "\n",
    "        _now_utc_=datetime.now(timezone('UTC'))\n",
    "        _now_local_=_now_utc_.astimezone(self._timezone_)\n",
    "\n",
    "        if local==True:\n",
    "            return _now_local_\n",
    "        else:\n",
    "            return _now_utc_\n",
    "\n",
    "\n",
    "    def __init__(self, verbose=2):\n",
    "\n",
    "        from datetime import datetime\n",
    "        from pytz import timezone\n",
    "        from tzlocal import get_localzone\n",
    "\n",
    "        self._strformat_ = []\n",
    "        self._timezone_ = []\n",
    "        self._timezone_ = get_localzone()\n",
    "        self._start_time_ = []\n",
    "        self._lap_label_ = []\n",
    "        self._lap_end_time_ = []\n",
    "        self._verbose_ = []\n",
    "        self._lap_duration_ = []\n",
    "        self._verbose_ = verbose\n",
    "        self._prior_start_time_ = []\n",
    "\n",
    "        strformat = \"%m/%d/%y - %I:%M:%S %p\"\n",
    "        self._strformat_ = strformat\n",
    "\n",
    "        if self._verbose_ > 0:\n",
    "            print(f'Clock created at {self.get_time().strftime(strformat)}.')\n",
    "\n",
    "        if self._verbose_>1:\n",
    "            print(f'\\tStart: clock.tic()\\tMark lap: clock.lap()\\tStop: clock.toc()\\n')\n",
    "\n",
    "\n",
    "\n",
    "    def mark_lap_list(self, label=None):\n",
    "        \"\"\"Used internally, appends the current laps' information when called by .lap()\n",
    "        self._lap_times_list_ = [['Lap #' , 'Start Time','Start Label','Stop Time', 'Stop Label', 'Duration']]\"\"\"\n",
    "        import bs_ds as bs\n",
    "#         print(self._prior_start_time_, self._lap_end_time_)\n",
    "        self._lap_times_list_.append([ self._lap_counter_ , # Lap #\n",
    "                                      (self._prior_start_time_).strftime(self._strformat_), # This Lap's Start Time\n",
    "                                      self._start_label_, # the start label for tic\n",
    "                                      self._lap_end_time_,#.strftime(self._strformat_), # stop clock time\n",
    "                                      self._lap_label_, # The Label passed with .lap()\n",
    "                                      self._lap_duration_.total_seconds()]) # the lap duration\n",
    "\n",
    "\n",
    "    def tic(self, label=None ):\n",
    "        \"Start the timer and display current time, appends label to the _list_lap_times.\"\n",
    "        from datetime import datetime\n",
    "        from pytz import timezone\n",
    "\n",
    "        self._start_time_ = self.get_time()\n",
    "        self._start_label_ = label\n",
    "        self._lap_counter_ = 0\n",
    "        self._prior_start_time_=self._start_time_\n",
    "        self._lap_times_list_=[]\n",
    "\n",
    "        # Initiate lap counter and list\n",
    "        self._lap_times_list_ = [['Lap #','Start Time','Start Label','Stop Time', 'Stop Label', 'Duration']]\n",
    "        self._lap_counter_ = 0\n",
    "        print(f'Clock started at {self._start_time_.strftime(self._strformat_)}')\n",
    "\n",
    "    def toc(self,label=None):\n",
    "        \"\"\"Stop the timer and displays results, appends label to final _list_lap_times entry\"\"\"\n",
    "        from datetime import datetime\n",
    "        from pytz import timezone\n",
    "        from tzlocal import get_localzone\n",
    "        from bs_ds import list2df\n",
    "\n",
    "\n",
    "        _final_end_time_ = self.get_time()\n",
    "        _total_time_ = _final_end_time_ - self._start_time_\n",
    "        _end_label_ = label\n",
    "\n",
    "        self._lap_counter_+=1\n",
    "        self._final_end_time_ = _final_end_time_\n",
    "        self._lap_label_=_end_label_\n",
    "        self._lap_end_time_ = _final_end_time_.strftime(self._strformat_)\n",
    "        self._lap_duration_ = _final_end_time_ - self._prior_start_time_\n",
    "        self._total_time_ = _total_time_\n",
    "        self.mark_lap_list()\n",
    "\n",
    "        # Append Summary Line\n",
    "        print(f'\\tLap #{self._lap_counter_} done @ {self._lap_end_time_}\\tlabel: {self._lap_label_:>{20}}\\tduration: {self._lap_duration_.total_seconds()} sec)')\n",
    "        self._lap_times_list_.append(['Start-End',self._start_time_.strftime(self._strformat_), self._start_label_,self._final_end_time_.strftime(self._strformat_),'Total Time:', self._total_time_.total_seconds() ])\n",
    "\n",
    "        df_lap_times = list2df(self._lap_times_list_,index_col='Lap #')\n",
    "        print(f'Total Time: {_total_time_}.')\n",
    "        if self._verbose_>1:\n",
    "            return df_lap_times\n",
    "\n",
    "\n",
    "\n",
    "    def lap(self, label=None):\n",
    "        \"\"\"Records time, duration, and label for current lap. Output display varies with clock verbose level.\n",
    "        Calls .mark_lap_list() to document results in clock._list_lap_ times.\"\"\"\n",
    "        from datetime import datetime\n",
    "\n",
    "        _end_time_ = self.get_time()\n",
    "\n",
    "        # Append the lap attribute list and counter\n",
    "        self._lap_label_ = label\n",
    "        self._lap_end_time_ = _end_time_.strftime(self._strformat_)\n",
    "        self._lap_counter_+=1\n",
    "        self._lap_duration_ = (_end_time_ - self._prior_start_time_)\n",
    "        # Now update the record\n",
    "        self.mark_lap_list()\n",
    "\n",
    "        # Now set next lap's new _prior_start\n",
    "        self._prior_start_time_=_end_time_\n",
    "\n",
    "        if self._verbose_>0:\n",
    "            print(f'\\tLap #{self._lap_counter_} done @ {self._lap_end_time_}\\tlabel: {self._lap_label_:>{20}}\\tduration: {self._lap_duration_.total_seconds()} sec)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clock created at 06/02/19 - 02:52:07 PM.\n",
      "\tStart: clock.tic()\tMark lap: clock.lap()\tStop: clock.toc()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clock=Clock(verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clock started at 06/02/19 - 02:52:42 PM\n",
      "\tLap #1 done @ 06/02/19 - 02:52:43 PM\tlabel:      lap 1 completed\tduration: 0.500465 sec)\n",
      "\tLap #2 done @ 06/02/19 - 02:52:44 PM\tlabel:      lap 2 completed\tduration: 1.200662 sec)\n",
      "\tLap #3 done @ 06/02/19 - 02:52:45 PM\tlabel:                lap 3\tduration: 0.500148 sec)\n",
      "\tLap #4 done @ 06/02/19 - 02:52:45 PM\tlabel:                final\tduration: 0.702204 sec)\n",
      "Total Time: 0:00:02.903479.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Start Time</th>\n",
       "      <th>Start Label</th>\n",
       "      <th>Stop Time</th>\n",
       "      <th>Stop Label</th>\n",
       "      <th>Duration</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lap #</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>06/02/19 - 02:52:42 PM</td>\n",
       "      <td>starting the process</td>\n",
       "      <td>06/02/19 - 02:52:43 PM</td>\n",
       "      <td>lap 1 completed</td>\n",
       "      <td>0.500465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>06/02/19 - 02:52:43 PM</td>\n",
       "      <td>starting the process</td>\n",
       "      <td>06/02/19 - 02:52:44 PM</td>\n",
       "      <td>lap 2 completed</td>\n",
       "      <td>1.200662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>06/02/19 - 02:52:44 PM</td>\n",
       "      <td>starting the process</td>\n",
       "      <td>06/02/19 - 02:52:45 PM</td>\n",
       "      <td>lap 3</td>\n",
       "      <td>0.500148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>06/02/19 - 02:52:45 PM</td>\n",
       "      <td>starting the process</td>\n",
       "      <td>06/02/19 - 02:52:45 PM</td>\n",
       "      <td>final</td>\n",
       "      <td>0.702204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Start-End</th>\n",
       "      <td>06/02/19 - 02:52:42 PM</td>\n",
       "      <td>starting the process</td>\n",
       "      <td>06/02/19 - 02:52:45 PM</td>\n",
       "      <td>Total Time:</td>\n",
       "      <td>2.903479</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Start Time           Start Label  \\\n",
       "Lap #                                                     \n",
       "1          06/02/19 - 02:52:42 PM  starting the process   \n",
       "2          06/02/19 - 02:52:43 PM  starting the process   \n",
       "3          06/02/19 - 02:52:44 PM  starting the process   \n",
       "4          06/02/19 - 02:52:45 PM  starting the process   \n",
       "Start-End  06/02/19 - 02:52:42 PM  starting the process   \n",
       "\n",
       "                        Stop Time       Stop Label  Duration  \n",
       "Lap #                                                         \n",
       "1          06/02/19 - 02:52:43 PM  lap 1 completed  0.500465  \n",
       "2          06/02/19 - 02:52:44 PM  lap 2 completed  1.200662  \n",
       "3          06/02/19 - 02:52:45 PM            lap 3  0.500148  \n",
       "4          06/02/19 - 02:52:45 PM            final  0.702204  \n",
       "Start-End  06/02/19 - 02:52:45 PM      Total Time:  2.903479  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "clock.tic('starting the process')\n",
    "time.sleep(0.5)\n",
    "\n",
    "clock.lap('lap 1 completed')\n",
    "time.sleep(1.2)\n",
    "\n",
    "clock.lap('lap 2 completed')\n",
    "time.sleep(0.5)\n",
    "\n",
    "clock.lap('lap 3')\n",
    "time.sleep(0.7)\n",
    "\n",
    "clock.toc('final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query=@realDonaldTrump, max=14999\n",
      "Downloading max14999 for @realDonaldTrump...\n",
      "Downloaded 81 tweets\n",
      "Downloaded 151 tweets\n",
      "Downloaded 229 tweets\n",
      "Downloaded 317 tweets\n",
      "Downloaded 391 tweets\n",
      "Downloaded 456 tweets\n",
      "Downloaded 528 tweets\n",
      "Downloaded 597 tweets\n",
      "Downloaded 677 tweets\n",
      "Downloaded 749 tweets\n",
      "Downloaded 821 tweets\n",
      "Downloaded 892 tweets\n",
      "Downloaded 964 tweets\n",
      "Downloaded 1043 tweets\n",
      "Downloaded 1121 tweets\n",
      "Downloaded 1205 tweets\n",
      "Downloaded 1275 tweets\n",
      "Downloaded 1346 tweets\n",
      "Downloaded 1421 tweets\n",
      "Downloaded 1497 tweets\n",
      "Downloaded 1573 tweets\n",
      "Downloaded 1658 tweets\n",
      "Downloaded 1744 tweets\n",
      "Downloaded 1818 tweets\n",
      "Downloaded 1899 tweets\n",
      "Downloaded 1978 tweets\n",
      "Downloaded 2061 tweets\n",
      "Downloaded 2138 tweets\n",
      "Downloaded 2209 tweets\n",
      "Downloaded 2285 tweets\n",
      "Downloaded 2367 tweets\n",
      "Downloaded 2444 tweets\n",
      "Downloaded 2520 tweets\n",
      "Downloaded 2609 tweets\n",
      "Downloaded 2695 tweets\n",
      "Downloaded 2769 tweets\n",
      "Downloaded 2843 tweets\n",
      "Downloaded 2925 tweets\n",
      "Downloaded 3010 tweets\n",
      "Downloaded 3084 tweets\n",
      "Downloaded 3157 tweets\n",
      "Downloaded 3236 tweets\n",
      "Downloaded 3314 tweets\n",
      "Downloaded 3388 tweets\n",
      "Downloaded 3470 tweets\n",
      "Downloaded 3553 tweets\n",
      "Downloaded 3633 tweets\n",
      "Downloaded 3716 tweets\n",
      "Downloaded 3798 tweets\n",
      "Downloaded 3877 tweets\n",
      "Downloaded 3957 tweets\n",
      "Downloaded 4025 tweets\n",
      "Downloaded 4097 tweets\n",
      "Downloaded 4178 tweets\n",
      "Downloaded 4255 tweets\n",
      "Downloaded 4326 tweets\n",
      "Downloaded 4403 tweets\n",
      "Downloaded 4481 tweets\n",
      "Downloaded 4563 tweets\n",
      "Downloaded 4633 tweets\n",
      "Downloaded 4706 tweets\n",
      "Downloaded 4788 tweets\n",
      "Downloaded 4862 tweets\n",
      "Downloaded 4926 tweets\n",
      "Downloaded 5004 tweets\n",
      "Downloaded 5087 tweets\n",
      "Downloaded 5161 tweets\n",
      "Downloaded 5238 tweets\n",
      "Downloaded 5306 tweets\n",
      "Downloaded 5385 tweets\n",
      "Downloaded 5465 tweets\n",
      "Downloaded 5545 tweets\n",
      "Downloaded 5618 tweets\n",
      "Downloaded 5700 tweets\n",
      "Downloaded 5778 tweets\n",
      "Downloaded 5859 tweets\n",
      "Downloaded 5933 tweets\n",
      "Downloaded 6013 tweets\n",
      "Downloaded 6095 tweets\n",
      "Downloaded 6169 tweets\n",
      "Downloaded 6245 tweets\n",
      "Downloaded 6313 tweets\n",
      "Downloaded 6395 tweets\n",
      "Downloaded 6470 tweets\n",
      "Downloaded 6550 tweets\n",
      "Downloaded 6627 tweets\n",
      "Downloaded 6710 tweets\n",
      "Downloaded 6793 tweets\n",
      "Downloaded 6868 tweets\n",
      "Downloaded 6947 tweets\n",
      "Downloaded 7022 tweets\n",
      "Downloaded 7101 tweets\n",
      "Downloaded 7180 tweets\n",
      "Downloaded 7266 tweets\n",
      "Downloaded 7360 tweets\n",
      "Downloaded 7435 tweets\n",
      "Downloaded 7516 tweets\n",
      "Downloaded 7609 tweets\n",
      "Downloaded 7687 tweets\n",
      "Downloaded 7765 tweets\n",
      "Downloaded 7846 tweets\n",
      "Downloaded 7929 tweets\n",
      "Downloaded 8020 tweets\n",
      "Downloaded 8106 tweets\n",
      "Downloaded 8196 tweets\n",
      "Downloaded 8265 tweets\n",
      "Downloaded 8354 tweets\n",
      "Downloaded 8425 tweets\n",
      "Downloaded 8508 tweets\n",
      "Downloaded 8587 tweets\n",
      "Downloaded 8664 tweets\n",
      "Downloaded 8731 tweets\n",
      "Downloaded 8809 tweets\n",
      "Downloaded 8880 tweets\n",
      "Downloaded 8962 tweets\n",
      "Downloaded 9033 tweets\n",
      "Downloaded 9112 tweets\n",
      "Downloaded 9199 tweets\n",
      "Downloaded 9278 tweets\n",
      "Downloaded 9349 tweets\n",
      "Downloaded 9435 tweets\n",
      "Downloaded 9514 tweets\n",
      "Downloaded 9587 tweets\n",
      "Downloaded 9653 tweets\n",
      "Downloaded 9744 tweets\n",
      "Downloaded 9820 tweets\n",
      "Downloaded 9901 tweets\n",
      "Downloaded 9990 tweets\n",
      "Downloaded 10060 tweets\n",
      "Downloaded 10140 tweets\n",
      "Downloaded 10225 tweets\n",
      "Downloaded 10302 tweets\n",
      "Downloaded 10380 tweets\n",
      "Downloaded 10459 tweets\n",
      "Downloaded 10532 tweets\n",
      "Downloaded 10613 tweets\n",
      "Downloaded 10689 tweets\n",
      "Downloaded 10775 tweets\n",
      "Downloaded 10856 tweets\n",
      "Downloaded 10941 tweets\n",
      "Downloaded 11011 tweets\n",
      "Downloaded 11096 tweets\n",
      "Downloaded 11186 tweets\n",
      "Downloaded 11268 tweets\n",
      "Downloaded 11355 tweets\n",
      "Downloaded 11425 tweets\n",
      "Downloaded 11503 tweets\n",
      "Downloaded 11580 tweets\n",
      "Downloaded 11665 tweets\n",
      "Downloaded 11752 tweets\n",
      "Downloaded 11833 tweets\n",
      "Downloaded 11913 tweets\n",
      "Downloaded 11991 tweets\n",
      "Downloaded 12066 tweets\n",
      "Downloaded 12141 tweets\n",
      "Downloaded 12217 tweets\n",
      "Downloaded 12290 tweets\n",
      "Downloaded 12365 tweets\n",
      "Downloaded 12444 tweets\n",
      "Downloaded 12530 tweets\n",
      "Downloaded 12605 tweets\n",
      "Downloaded 12672 tweets\n",
      "Downloaded 12745 tweets\n",
      "Downloaded 12812 tweets\n",
      "Downloaded 12882 tweets\n",
      "Downloaded 12954 tweets\n",
      "Downloaded 13027 tweets\n",
      "Downloaded 13090 tweets\n",
      "Downloaded 13171 tweets\n",
      "Downloaded 13256 tweets\n",
      "Downloaded 13335 tweets\n",
      "Downloaded 13417 tweets\n",
      "Downloaded 13487 tweets\n",
      "Downloaded 13558 tweets\n",
      "Downloaded 13629 tweets\n",
      "Downloaded 13709 tweets\n",
      "Downloaded 13782 tweets\n",
      "Downloaded 13861 tweets\n",
      "Downloaded 13938 tweets\n",
      "Downloaded 14013 tweets\n",
      "Downloaded 14088 tweets\n",
      "Downloaded 14169 tweets\n",
      "Downloaded 14251 tweets\n",
      "Downloaded 14328 tweets\n",
      "Downloaded 14396 tweets\n",
      "Downloaded 14471 tweets\n",
      "Downloaded 14553 tweets\n",
      "Downloaded 14624 tweets\n",
      "Downloaded 14708 tweets\n",
      "Downloaded 14780 tweets\n",
      "Downloaded 14855 tweets\n",
      "Downloaded 14929 tweets\n",
      "Downloaded 15008 tweets\n",
      "Downloaded 15008 tweets, Saved to top_tweets_by_at.txt\n",
      "\n",
      "Query=@midnight, max=9991\n",
      "Downloading max9991 for @midnight...\n",
      "Downloaded 92 tweets\n",
      "Downloaded 174 tweets\n",
      "Downloaded 219 tweets\n",
      "No more tweets found\n",
      "Downloaded 219 tweets, Saved to top_tweets_by_at.txt\n",
      "\n",
      "Query=@POTUS, max=5633\n",
      "Downloading max5633 for @POTUS...\n",
      "Downloaded 54 tweets\n",
      "Downloaded 100 tweets\n",
      "Downloaded 158 tweets\n",
      "Downloaded 202 tweets\n",
      "Downloaded 246 tweets\n",
      "Downloaded 299 tweets\n",
      "Downloaded 358 tweets\n",
      "Downloaded 410 tweets\n",
      "Downloaded 457 tweets\n",
      "Downloaded 501 tweets\n",
      "Downloaded 553 tweets\n",
      "Downloaded 601 tweets\n",
      "Downloaded 660 tweets\n",
      "Downloaded 713 tweets\n",
      "Downloaded 770 tweets\n",
      "Downloaded 822 tweets\n",
      "Downloaded 877 tweets\n",
      "Downloaded 941 tweets\n",
      "Downloaded 991 tweets\n",
      "Downloaded 1039 tweets\n",
      "Downloaded 1087 tweets\n",
      "Downloaded 1141 tweets\n",
      "Downloaded 1198 tweets\n",
      "Downloaded 1244 tweets\n",
      "Downloaded 1296 tweets\n",
      "Downloaded 1347 tweets\n",
      "Downloaded 1396 tweets\n",
      "Downloaded 1450 tweets\n",
      "Downloaded 1500 tweets\n",
      "Downloaded 1556 tweets\n",
      "Downloaded 1608 tweets\n",
      "Downloaded 1665 tweets\n",
      "Downloaded 1709 tweets\n",
      "Downloaded 1762 tweets\n",
      "Downloaded 1810 tweets\n",
      "Downloaded 1865 tweets\n",
      "Downloaded 1921 tweets\n",
      "Downloaded 1981 tweets\n",
      "Downloaded 2036 tweets\n",
      "Downloaded 2081 tweets\n",
      "Downloaded 2135 tweets\n",
      "Downloaded 2192 tweets\n",
      "Downloaded 2247 tweets\n",
      "Downloaded 2299 tweets\n",
      "Downloaded 2346 tweets\n",
      "Downloaded 2397 tweets\n",
      "Downloaded 2441 tweets\n",
      "Downloaded 2492 tweets\n",
      "Downloaded 2544 tweets\n",
      "Downloaded 2591 tweets\n",
      "Downloaded 2640 tweets\n",
      "Downloaded 2674 tweets\n",
      "Downloaded 2723 tweets\n",
      "Downloaded 2780 tweets\n",
      "Downloaded 2826 tweets\n",
      "Downloaded 2872 tweets\n",
      "Downloaded 2926 tweets\n",
      "Downloaded 2983 tweets\n",
      "Downloaded 3033 tweets\n",
      "Downloaded 3086 tweets\n",
      "Downloaded 3154 tweets\n",
      "Downloaded 3207 tweets\n",
      "Downloaded 3257 tweets\n",
      "Downloaded 3315 tweets\n",
      "Downloaded 3374 tweets\n",
      "Downloaded 3416 tweets\n",
      "Downloaded 3468 tweets\n",
      "Downloaded 3517 tweets\n",
      "Downloaded 3581 tweets\n",
      "Downloaded 3632 tweets\n",
      "Downloaded 3688 tweets\n",
      "Downloaded 3740 tweets\n",
      "Downloaded 3788 tweets\n",
      "Downloaded 3848 tweets\n",
      "Downloaded 3897 tweets\n",
      "Downloaded 3952 tweets\n",
      "Downloaded 4003 tweets\n",
      "Downloaded 4047 tweets\n",
      "Downloaded 4081 tweets\n",
      "Downloaded 4129 tweets\n",
      "Downloaded 4177 tweets\n",
      "Downloaded 4223 tweets\n",
      "Downloaded 4274 tweets\n",
      "Downloaded 4329 tweets\n",
      "Downloaded 4380 tweets\n",
      "Downloaded 4436 tweets\n",
      "Downloaded 4481 tweets\n",
      "Downloaded 4523 tweets\n",
      "Downloaded 4577 tweets\n",
      "Downloaded 4634 tweets\n",
      "Downloaded 4691 tweets\n",
      "Downloaded 4741 tweets\n",
      "Downloaded 4791 tweets\n",
      "Downloaded 4831 tweets\n",
      "Downloaded 4881 tweets\n",
      "Downloaded 4928 tweets\n",
      "Downloaded 4975 tweets\n",
      "Downloaded 5026 tweets\n",
      "Downloaded 5074 tweets\n",
      "Downloaded 5131 tweets\n",
      "Downloaded 5184 tweets\n",
      "Downloaded 5249 tweets\n",
      "Downloaded 5294 tweets\n",
      "Downloaded 5353 tweets\n",
      "Downloaded 5415 tweets\n",
      "Downloaded 5478 tweets\n",
      "Downloaded 5533 tweets\n",
      "Downloaded 5598 tweets\n",
      "Downloaded 5654 tweets\n",
      "Downloaded 5654 tweets, Saved to top_tweets_by_at.txt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Extract tweets for top @'s, while matching the distribution of top @'s\n",
    "\n",
    "filename = 'top_tweets_by_at.txt'\n",
    "\n",
    "for q in query_ats[:3]:\n",
    "    searchQuery = q[0]\n",
    "    maxTweets = q[1]\n",
    "    print(f'Query={searchQuery}, max={maxTweets}')\n",
    "    search_twitter_api(searchQuery, maxTweets, fName=filename)\n",
    "#     time.sleep(1)\n",
    "    \n",
    "# toc(t0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets = pd.read_json('top_tweets_by_at_06022019.txt', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contributors</th>\n",
       "      <th>coordinates</th>\n",
       "      <th>created_at</th>\n",
       "      <th>display_text_range</th>\n",
       "      <th>entities</th>\n",
       "      <th>extended_entities</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>favorited</th>\n",
       "      <th>full_text</th>\n",
       "      <th>geo</th>\n",
       "      <th>...</th>\n",
       "      <th>quoted_status</th>\n",
       "      <th>quoted_status_id</th>\n",
       "      <th>quoted_status_id_str</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>retweeted</th>\n",
       "      <th>retweeted_status</th>\n",
       "      <th>source</th>\n",
       "      <th>truncated</th>\n",
       "      <th>user</th>\n",
       "      <th>withheld_in_countries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>2019-06-02 15:32:39</td>\n",
       "      <td>[0, 140]</td>\n",
       "      <td>{'hashtags': [], 'symbols': [], 'urls': [], 'u...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>RT @realDonaldTrump: When you are the “Piggy B...</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24356</td>\n",
       "      <td>False</td>\n",
       "      <td>{'contributors': None, 'coordinates': None, 'c...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>False</td>\n",
       "      <td>{'contributors_enabled': False, 'created_at': ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>2019-06-02 15:32:39</td>\n",
       "      <td>[31, 81]</td>\n",
       "      <td>{'hashtags': [], 'symbols': [], 'urls': [{'dis...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>@realDonaldTrump @CNN @nytimes Here it is, you...</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>False</td>\n",
       "      <td>{'contributors_enabled': False, 'created_at': ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>2019-06-02 15:32:39</td>\n",
       "      <td>[31, 79]</td>\n",
       "      <td>{'hashtags': [], 'symbols': [], 'urls': [], 'u...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>@realDonaldTrump @CNN @nytimes You LITERALLY s...</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/#!/download/ipad\" ...</td>\n",
       "      <td>False</td>\n",
       "      <td>{'contributors_enabled': False, 'created_at': ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>2019-06-02 15:32:39</td>\n",
       "      <td>[0, 140]</td>\n",
       "      <td>{'hashtags': [], 'symbols': [], 'urls': [], 'u...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>RT @realDonaldTrump: People have been saying f...</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12978</td>\n",
       "      <td>False</td>\n",
       "      <td>{'contributors': None, 'coordinates': None, 'c...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>False</td>\n",
       "      <td>{'contributors_enabled': False, 'created_at': ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>2019-06-02 15:32:39</td>\n",
       "      <td>[47, 47]</td>\n",
       "      <td>{'hashtags': [], 'media': [{'display_url': 'pi...</td>\n",
       "      <td>{'media': [{'display_url': 'pic.twitter.com/H5...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>@KevinJacksonTBS @realDonaldTrump @CNN @nytime...</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>False</td>\n",
       "      <td>{'contributors_enabled': False, 'created_at': ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   contributors coordinates          created_at display_text_range  \\\n",
       "0           NaN        None 2019-06-02 15:32:39           [0, 140]   \n",
       "1           NaN        None 2019-06-02 15:32:39           [31, 81]   \n",
       "2           NaN        None 2019-06-02 15:32:39           [31, 79]   \n",
       "3           NaN        None 2019-06-02 15:32:39           [0, 140]   \n",
       "4           NaN        None 2019-06-02 15:32:39           [47, 47]   \n",
       "\n",
       "                                            entities  \\\n",
       "0  {'hashtags': [], 'symbols': [], 'urls': [], 'u...   \n",
       "1  {'hashtags': [], 'symbols': [], 'urls': [{'dis...   \n",
       "2  {'hashtags': [], 'symbols': [], 'urls': [], 'u...   \n",
       "3  {'hashtags': [], 'symbols': [], 'urls': [], 'u...   \n",
       "4  {'hashtags': [], 'media': [{'display_url': 'pi...   \n",
       "\n",
       "                                   extended_entities  favorite_count  \\\n",
       "0                                                NaN               0   \n",
       "1                                                NaN               0   \n",
       "2                                                NaN               0   \n",
       "3                                                NaN               0   \n",
       "4  {'media': [{'display_url': 'pic.twitter.com/H5...               0   \n",
       "\n",
       "   favorited                                          full_text   geo  ...  \\\n",
       "0      False  RT @realDonaldTrump: When you are the “Piggy B...  None  ...   \n",
       "1      False  @realDonaldTrump @CNN @nytimes Here it is, you...  None  ...   \n",
       "2      False  @realDonaldTrump @CNN @nytimes You LITERALLY s...  None  ...   \n",
       "3      False  RT @realDonaldTrump: People have been saying f...  None  ...   \n",
       "4      False  @KevinJacksonTBS @realDonaldTrump @CNN @nytime...  None  ...   \n",
       "\n",
       "   quoted_status  quoted_status_id quoted_status_id_str  retweet_count  \\\n",
       "0            NaN               NaN                  NaN          24356   \n",
       "1            NaN               NaN                  NaN              0   \n",
       "2            NaN               NaN                  NaN              0   \n",
       "3            NaN               NaN                  NaN          12978   \n",
       "4            NaN               NaN                  NaN              0   \n",
       "\n",
       "   retweeted                                   retweeted_status  \\\n",
       "0      False  {'contributors': None, 'coordinates': None, 'c...   \n",
       "1      False                                                NaN   \n",
       "2      False                                                NaN   \n",
       "3      False  {'contributors': None, 'coordinates': None, 'c...   \n",
       "4      False                                                NaN   \n",
       "\n",
       "                                              source  truncated  \\\n",
       "0  <a href=\"http://twitter.com/download/iphone\" r...      False   \n",
       "1  <a href=\"http://twitter.com/download/iphone\" r...      False   \n",
       "2  <a href=\"http://twitter.com/#!/download/ipad\" ...      False   \n",
       "3  <a href=\"http://twitter.com/download/iphone\" r...      False   \n",
       "4  <a href=\"http://twitter.com/download/iphone\" r...      False   \n",
       "\n",
       "                                                user withheld_in_countries  \n",
       "0  {'contributors_enabled': False, 'created_at': ...                   NaN  \n",
       "1  {'contributors_enabled': False, 'created_at': ...                   NaN  \n",
       "2  {'contributors_enabled': False, 'created_at': ...                   NaN  \n",
       "3  {'contributors_enabled': False, 'created_at': ...                   NaN  \n",
       "4  {'contributors_enabled': False, 'created_at': ...                   NaN  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets['date_published'] = pd.to_datetime(df_tweets['created_at'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Timestamp('2019-05-23 18:12:37'), Timestamp('2019-06-02 16:30:29'))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets['date_published'].min(), df_tweets['date_published'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env-ext",
   "language": "python",
   "name": "learn-env-ext"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
